[{"content":"In NLP, it takes the form of anisotropy, a singular property of hidden representations which makes them unexpectedly close to each other in terms of angular distance (cosine-similarity). Anisotropy has been widely observed among self-supervised models based on Transformers -\u0026gt; recent literature says it could be related to optimizing the [[cross entropy loss[https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html]]\nAnisotropy in pretrained BERTs CharacterBERT CANINE -\u0026gt; s downsampling contextualized character representations via astrided convolution before feeding them to aTransformers. It can be trained either with a subword-based objective (CANINE-s) or with a character-level one (CANINE-c). MANTa-LM-\u0026gt; is based on a differentiable segmentation and embed- ding module added before an encoder-decoder model in the style of T5 ByT5 -\u0026gt; is a version of T5 trained at byte - level. Metric used is COSINE SIMILARITY\nNeither of these architectures should suffer from out-of-vocabulary tokens in the process of creating representations. The models that predict at word or sub-word level (CharacterBERT and CANINE-s) could have the cross-entropy loss systematically pushing away rare item representations. However, it is rather unclear why it would imply an embedding drift at deeper layers. Hence, if anisotropy was only caused by the presence of unused or rare subwords, those character-level models should be much less prone to this issue. All models were tested on the [[WikiText-103 corpus]] ![[Pasted image 20241007160113.png]] All models show high levels of anisotropy, even character-based ones!\nLinguistic properties only? Authors proceed to try speech and vision models to show anisotropy is not related to subtokens themselves!\nHuBERT MiT DEiT BEiT ![[Pasted image 20241007161746.png]] Speech models ![[Pasted image 20241007161804.png]] Vision models Video goes a little better (?)\nConvolutional NN (vision based) ResNet-\u0026gt; Apparently this models have isotropic representations! *EfficientNet ConvNeXt VAN This could partially be explained by the fact that the batch normalization (Ioffe and Szegedy, 2015) used in some of these models mitigates a posteriori the drift effect by re- moving the mean component of the representations. However, the ConvNeXt model also seems to use isotropic representations while not using batch normalization, which shows that this is not the only factor in the isotropic behavior of these models. ![[Pasted image 20241007162858.png]] Correlation ? They also find that spearman\u0026rsquo;s correlation doesn\u0026rsquo;t often correlate with the drift (norm) of the token embeddings!\nExploring the representation drift Here, with no assumption on data distribution and no training of the Transformer block. They add some bias b to the input representation x . Specifically, we study the average norm of the input representations $E(||xi + b||2$ ) against the average norm of the output representations $E(||T (xi + b)||{2}$ )$ . We also retrieve the self-attention scores before the softmax operation.\n![[Pasted image 20241007164834.png]]No matter the bias, output representations have higher cosine similarity .\n![[Pasted image 20241007165048.png]] There is a fixed point! $$ E_{x,bN }∗ (||xi + b_N ∗ ||) = E_{x,bN} ∗ (||T (x_i + b_{N ∗})||)$$ This hints that the model’s representations stabilize when their norm is close to this fixed point!\nThe transformers Block We look closely at the self-attention operation. As the norm of the average $x$ of the input increases , also $Q$ and $K$ increase. ![[Pasted image 20241007170230.png]]\nImpact of the drift we retrieve softmax values in the self-attention block and for each position, they ex- tract the maximum, the median and the minimum. as the input bias norm increases, the self-attention softmax distributions tend to become ess entropic, evolving towards higher maximal probabilities and lower minimal probabilities. ![[Pasted image 20241008160615.png]]\n","permalink":"https://ldomenichelli.github.io/posts/post2/","summary":"\u003cp\u003eIn NLP, it takes the form of anisotropy, a singular property of hidden representations which makes them unexpectedly close to each other in terms of angular distance (cosine-similarity).\nAnisotropy has been widely observed among self-supervised models based on Transformers -\u0026gt; recent literature says it could be related to optimizing the [[cross entropy loss[https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html]]\u003c/p\u003e\n\u003ch3 id=\"anisotropy-in-pretrained-berts\"\u003eAnisotropy in pretrained BERTs\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eCharacterBERT\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eCANINE\u003c/em\u003e -\u0026gt; s downsampling contextualized character representations via astrided convolution before feeding them to aTransformers. It can be trained either with a subword-based objective (CANINE-s) or with a character-level one (CANINE-c).\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eMANTa-LM\u003c/em\u003e-\u0026gt; is based on a differentiable segmentation and embed- ding module added before an encoder-decoder model in the style of T5\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eByT5\u003c/em\u003e -\u0026gt; is a version of T5 trained at byte - level.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eMetric used is COSINE SIMILARITY\u003c/strong\u003e\u003c/p\u003e","title":""},{"content":"What is Abalone? Have you ever tried pushing your opponent off a cliff… in a friendly way? If that sounds intriguing, let me introduce you to Abalone, a strategy board game where you literally push your way to victory! Created in 1987 by Michel Lalet and Laurent Lévi, this two-player game is a unique blend of simplicity and depth that has earned it a spot in the hearts of board game lovers worldwide.\nThe game’s name comes from the abalone, a type of mollusk known for its \u0026ldquo;ear-shaped\u0026rdquo; shell. The Italian name for the game, aliotide, combines the Latin prefix \u0026ldquo;ab-\u0026rdquo; (meaning \u0026ldquo;from\u0026rdquo; or \u0026ldquo;away\u0026rdquo;) and the English word \u0026ldquo;alone,\u0026rdquo; hinting at the isolated struggle between two opponents.\nIn Abalone, two players compete on a hexagonal board with 14 marbles each: white for one player, black for the other. The aim is straightforward: be the first to push six of your opponent\u0026rsquo;s marbles off the board. But as you\u0026rsquo;ll soon discover, achieving this goal requires careful planning, tactical moves, and a deep understanding of positioning.\nGame Components and Setup The game is played on a hexagonal board with 61 circular positions arranged in rows:\nFigure 1: Board layout\nEach player starts with 14 marbles, and the initial setup (shown below) places these marbles in a specific formation, primed for strategic movement.\nFigure 2: Initial setup\nEach position on the board is labeled using a grid system with letters and numbers, allowing players to communicate moves easily.\nBasic Rules and Movements In Abalone, players take turns making a single move per turn. Here are the core rules:\nMoving a Marble: On your turn, you can move one marble to any adjacent, empty spot on the board. Line and Lateral Moves: You can also move a line of two or three marbles as long as they are aligned in the same direction. This can be done in two ways: In-Line Movement: Move all marbles in the line forward in the same direction. Lateral Movement: Shift all marbles in the line to the side without changing their orientation. Sumito (Pushing Marbles): If your marbles outnumber the adjacent marbles of your opponent in a line, you can push them. For instance, two marbles can push one, and three can push two. Pushing is only possible if there’s an empty spot behind the opposing marble(s) for them to move into. Special Positioning: \u0026ldquo;Pac\u0026rdquo; and Strategic Pushes The concept of pac is crucial for mastering Abalone. When white and black marbles are aligned in equal numbers, neither player can push the other (this creates a \u0026ldquo;pac\u0026rdquo; or standoff). This means that understanding numerical superiority and positioning is essential.\nFor example, in a scenario where three black marbles face three white marbles, no push is possible. However, a setup with three black marbles against two white marbles allows the black player to push forward. This rule creates opportunities to set up defenses and traps, making the game highly tactical.\nKey Strategies for Winning To succeed in Abalone, keep these strategies in mind:\nControl the Center: Marbles near the edges are at greater risk of being pushed out. Maintaining a central position allows flexibility and reduces the likelihood of getting cornered. Set Up Sumito Opportunities: Since pushing depends on having more marbles in a line, positioning your marbles strategically to outnumber opponents in key areas is vital. Avoid Isolation: Isolated marbles are easy targets for a Sumito. Keep your marbles grouped to maintain pushing power and defend against your opponent’s moves. Force a Pac: Sometimes, creating a standoff situation (pac) can disrupt your opponent’s plans, giving you time to reposition your marbles. Now, enjoy this 90\u0026rsquo;s commercial or play the game online while I\u0026rsquo;m writing the rest of the rules!\n","permalink":"https://ldomenichelli.github.io/games/abalone/","summary":"\u003ch2 id=\"what-is-abalone\"\u003eWhat is Abalone?\u003c/h2\u003e\n\u003cp\u003eHave you ever tried pushing your opponent off a cliff… in a friendly way? If that sounds intriguing, let me introduce you to \u003cem\u003eAbalone\u003c/em\u003e, a strategy board game where you literally push your way to victory! Created in 1987 by Michel Lalet and Laurent Lévi, this two-player game is a unique blend of simplicity and depth that has earned it a spot in the hearts of board game lovers worldwide.\u003c/p\u003e","title":"Abalone"},{"content":" Me fr fr.\nWelcome to my study space! I\u0026rsquo;m Lucia, a first-year PhD student in AI at UniPi.\nHere, I collect personal notes on various topics I’m learning. They’re written for me, but might be helpful to others, too. Enjoy reading!\n","permalink":"https://ldomenichelli.github.io/about/","summary":"Information about me.","title":"About this site"},{"content":"Achi: A Traditional African Game Achi is a traditional board game originating from Ghana, and is similar to the game of \u0026ldquo;Nine Men\u0026rsquo;s Morris\u0026rdquo; (or \u0026ldquo;Mill\u0026rdquo;), but it has a unique structure and rules. The game is widely played in several African countries, including Nigeria, Senegal (where it is known as Care), and others. It is classified among alignment games, which also include games like Tapatan, Tant Fant, Shisima, and Pong Hau K\u0026rsquo;i.\nObjective: The goal of Achi is to form an uninterrupted line of three pieces of the same color, placed on the same horizontal, vertical, or diagonal line. Once a player achieves this, the game ends immediately, and that player wins.\nEquipment: The game consists of:\nA board with 9 intersections (as shown in the diagram). 8 pieces: 4 white and 4 black. Pieces are placed on the intersections, not within the squares of the grid. Players: The game is played by two players, who take turns.\nRules: There are two main phases in the game: the Placement Phase and the Movement Phase.\n1. Placement Phase: During the Placement Phase, players take turns placing one piece at a time on any available intersection on the board. Pieces cannot be moved during this phase. This phase ends once all 8 pieces (4 for each player) have been placed on the board. After this phase, there will be only one empty intersection left on the board. The initial setup leaves the board empty, and either player can start. 2. Movement Phase: Once all pieces are placed, the game transitions into the Movement Phase. From the fifth move onwards, players can move their pieces. A piece may be moved to an adjacent intersection (orthogonally or diagonally), as long as the target intersection is empty. Players continue to move their pieces, aiming to align three of their pieces in a row (horizontally, vertically, or diagonally). The game ends as soon as a player forms a line of three pieces of their color, either during the Placement Phase or the Movement Phase. ","permalink":"https://ldomenichelli.github.io/games/achi/","summary":"\u003ch1 id=\"achi-a-traditional-african-game\"\u003eAchi: A Traditional African Game\u003c/h1\u003e\n\u003cp\u003eAchi is a traditional board game originating from Ghana, and is similar to the game of \u0026ldquo;Nine Men\u0026rsquo;s Morris\u0026rdquo; (or \u0026ldquo;Mill\u0026rdquo;), but it has a unique structure and rules. The game is widely played in several African countries, including Nigeria, Senegal (where it is known as \u003cem\u003eCare\u003c/em\u003e), and others. It is classified among alignment games, which also include games like \u003cem\u003eTapatan\u003c/em\u003e, \u003cem\u003eTant Fant\u003c/em\u003e, \u003cem\u003eShisima\u003c/em\u003e, and \u003cem\u003ePong Hau K\u0026rsquo;i\u003c/em\u003e.\u003c/p\u003e","title":"Achi"},{"content":"","permalink":"https://ldomenichelli.github.io/posts/post1/","summary":"","title":"Coming soon"},{"content":"Quantum Computing - Intro Quantum computing leverages the principles of quantum mechanics to solve problems that are difficult or impossible for classical computers. In Python, quantum computing can be explored through various frameworks and libraries, such as IBM\u0026rsquo;s Qiskit and Google\u0026rsquo;s Cirq.\nImport essential components from Qiskit, for handling quantum circuits and visualization.\nfrom qiskit import QuantumCircuit, Aer, execute from qiskit.visualization import plot_bloch_vector In quantum computing, a qubit is the fundamental unit of quantum information. You can create a quantum circuit with a single qubit like this:\nqc = QuantumCircuit(1) Quantum gates manipulate qubits, changing their states. Quantum gates are represented as unitary matrices that transform qubit states in vector form.\n$$ U^\\dagger U = U U^\\dagger = I $$\nWhere:\n$ U^\\dagger $ is the conjugate transpose (Hermitian adjoint) of the matrix $U$. $I$ is the identity matrix of the same dimension as $U$. Unitary matrices preserve the length (norm) of quantum states, which is essential for ensuring that quantum computations are physically meaningful.\nBasic Quantum Gates Pauli-X Gate The X-gate, akin to the classical NOT gate, flips a qubit’s state.\nMatrix Representation:\n$$ X = \\begin{pmatrix} 0 \u0026amp; 1 \\ 1 \u0026amp; 0 \\end{pmatrix} $$ Action: Transforms$|0\\rangle$ to $|1\\rangle$ and vice versa. Pauli-Y and Pauli-Z Gates The Y and Z gates provide further qubit manipulation along different axes.\nY-Gate Matrix:\n$$ Y = \\begin{pmatrix} 0 \u0026amp; -i \\ i \u0026amp; 0 \\end{pmatrix} $$ Z-Gate Matrix:\n$$ Z = \\begin{pmatrix} 1 \u0026amp; 0 \\ 0 \u0026amp; -1 \\end{pmatrix} $$\nEffect: The Y-gate performs a phase rotation, while the Z-gate flips the phase of the ($|1\\rangle$ state. Hadamard Gate (H) The Hadamard gate creates a superposition from a basis state, equalizing the probabilities of measuring $|0\\rangle$ or $|1\\rangle$.\nMatrix Representation:\n$$ H = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \u0026amp; 1 \\ 1 \u0026amp; -1 \\end{pmatrix} $$ Effect: Transforms$|0\\rangle$ into\n$$ \\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}} $$ a superposition state. Phase Gate (S and T) The Phase Gate (S) and T-Gate add specific phase rotations, essential in quantum Fourier transforms.\nS-Gate Matrix:\n$$ S = \\begin{pmatrix} 1 \u0026amp; 0 \\ 0 \u0026amp; i \\end{pmatrix} $$ T-Gate Matrix:\n$$ T = \\begin{pmatrix} 1 \u0026amp; 0 \\ 0 \u0026amp; e^{i\\pi/4} \\end{pmatrix} $$\nPurpose: These gates modify the phase of qubits, supporting interference and entanglement. 3. Multi-Qubit Gates CNOT Gate The Controlled NOT (CNOT) gate acts on two qubits, flipping the second qubit (target) if the first qubit (control) is $|1\\rangle$.\nMatrix Representation:\n$$ CNOT = \\begin{pmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\ 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\ 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\end{pmatrix} $$\nFunction: Creates entanglement, foundational for quantum cryptography and algorithms like Grover’s and Shor’s. Toffoli and SWAP Gates These gates expand control capabilities in multi-qubit systems.\nToffoli (CCNOT): Three-qubit gate; flips the third qubit if the first two are (|1\\rangle). SWAP Gate: Exchanges the states of two qubits. ","permalink":"https://ldomenichelli.github.io/random/quantum/","summary":"\u003ch2 id=\"quantum-computing---intro\"\u003eQuantum Computing - Intro\u003c/h2\u003e\n\u003cp\u003eQuantum computing leverages the principles of quantum mechanics to solve problems that are difficult or impossible for classical computers. In Python, quantum computing can be explored through various frameworks and libraries, such as IBM\u0026rsquo;s Qiskit and Google\u0026rsquo;s Cirq.\u003c/p\u003e\n\u003cp\u003eImport essential components from Qiskit, for handling quantum circuits and visualization.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efrom qiskit import QuantumCircuit, Aer, execute\nfrom qiskit.visualization import plot_bloch_vector\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn quantum computing, a qubit is the fundamental unit of quantum information. You can create a quantum circuit with a single qubit like this:\u003c/p\u003e","title":"Quantum Computing - Intro "}]