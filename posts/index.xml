<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>lucia&#39;s notes</title>
    <link>https://ldomenichelli.github.io/posts/</link>
    <description>Recent content on lucia&#39;s notes</description>
    <image>
      <title>lucia&#39;s notes</title>
      <url>https://ldomenichelli.github.io/logo.png</url>
      <link>https://ldomenichelli.github.io/logo.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://ldomenichelli.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>‚ùÑÔ∏è HPLT √ó NLPL Winter School</title>
      <link>https://ldomenichelli.github.io/posts/post5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post5/</guid>
      <description>Short notes and slide links from the Winter School in Skeikampen, Norway (Feb‚ÄØ10‚Äë14,‚ÄØ2025).</description>
    </item>
    
    <item>
      <title>Embeddings space ñ¶π◊Ç ‚ÇäÀö‚äπ‚ãÜ</title>
      <link>https://ldomenichelli.github.io/posts/post1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post1/</guid>
      <description>&lt;p&gt;Understanding the &lt;strong&gt;curse of dimensionality&lt;/strong&gt; requires more than just examining the representational aspect of data. A key insight lies in the concept of &lt;strong&gt;intrinsic dimensionality (ID)&lt;/strong&gt;‚Äîthe number of degrees of freedom within a data manifold or subspace. This ID is often independent of the dimensionality of the space in which the data is embedded. As a result, ID serves as a foundation for dimensionality reduction, which improves similarity measures and enhances the scalability of machine learning and data mining methods.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Geometric Deep Learning</title>
      <link>https://ldomenichelli.github.io/posts/post7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post7/</guid>
      <description>Some notes on geometric deep learning</description>
    </item>
    
    <item>
      <title>Optimal Transport üï∑Ô∏è and Wasserstein distance</title>
      <link>https://ldomenichelli.github.io/posts/post2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post2/</guid>
      <description>Intro to Optimal Transport with spider Cedric (Villani) :) üï∑Ô∏è</description>
    </item>
    
    <item>
      <title>Statistical Learning and Large Data üìä</title>
      <link>https://ldomenichelli.github.io/posts/post8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post8/</guid>
      <description>&lt;p&gt;Here are the slides and notes on the course hold by Prof. Chiaromonte at Sant&amp;rsquo;Anna University, Pisa.
&lt;embed src=&#34;https://ldomenichelli.github.io/SLLD_new.pdf&#34; width=&#34;100%&#34; height=&#34;800px&#34; type=&#34;application/pdf&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Time Series üìà</title>
      <link>https://ldomenichelli.github.io/posts/post9/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post9/</guid>
      <description>&lt;h1 id=&#34;predictive-models-for-time-series-analysis&#34;&gt;Predictive Models for Time Series Analysis&lt;/h1&gt;
&lt;p&gt;Time series analysis involves understanding data points collected over time, where the order of observations matters. By modeling the temporal dependencies, we can make forecasts, detect anomalies, cluster similar patterns, and perform classification or regression tasks on sequence data. Below is an extended overview with added details.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-introduction-to-time-series-analysis&#34;&gt;1. Introduction to Time Series Analysis&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;time series&lt;/strong&gt; is typically defined as:
$$
T = { x_1, x_2, \dots, x_m }
$$
where each observation ( x_i ) is recorded at a specific time ( t_i ), usually at uniform intervals.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Topological Data Analysis üåê</title>
      <link>https://ldomenichelli.github.io/posts/post4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://ldomenichelli.github.io/posts/post4/</guid>
      <description>On the HPLT &amp;amp; NLPL Winter School</description>
    </item>
    
  </channel>
</rss>
